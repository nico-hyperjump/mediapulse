---
title: Scheduler/Orchestrator
---

## Purpose

**The Scheduler/Orchestrator is NOT an agent** - it is a long-running BullMQ worker that monitors the database for schedules and executes them automatically. The orchestrator is **completely generic** and **database-driven**—it has no hardcoded agent configurations. Admins create schedules and pipelines through the admin interface, and the orchestrator dynamically discovers agents and executes jobs based on database configurations.

The scheduler runs continuously as a BullMQ worker, polling the database for schedules that need to be executed (once or repeating with cron/interval). When a schedule's time arrives, the orchestrator invokes agents via HTTP endpoints. Agents are **language-agnostic** and can run anywhere (containers, cloud functions, n8n workflows, etc.) as long as they follow the [Agent Specification](./agent-specification). Agents execute asynchronously, reading from and writing to the database. The orchestrator does not wait for agent completion but tracks job status through the database.

**Note**: Agents are one-off executions. When a schedule triggers, the scheduler invokes the agent's HTTP endpoint. The agent runs, completes its job, writes results to the database, and then shuts down. There are no long-running agent instances to manage.

**Key Responsibilities**:
- Dynamically discover agents from the database (no hardcoded agent list)
- Execute schedules created by admins (stored in `Schedule` table)
- **Support ID expansion** for agents that accept ID parameters (e.g., `tickerId`, `userId`)
  - When `value: 'all'` is set, query database table and create multiple job inputs
  - Process jobs in batches with stagger delay to avoid overloading agents
- Orchestrate multi-agent pipelines with job dependencies (stored in `Pipeline` table)
- Manage different schedule types: once or repeating (cron/interval)
- Poll database continuously for schedules that need execution
- Invoke agent HTTP endpoints with proper parameters and authentication
- Monitor job status through database queries (`AgentJobExecution` table)
- Handle retries for failed jobs by re-invoking agent endpoints
- Validate agent responses and handle agent failures gracefully

## Database Schema

The scheduler uses the following database tables (stored in PostgreSQL):

### `AgentRegistry`
Stores **agent type metadata** (not version-specific), including agent HTTP endpoint URLs and configuration. The scheduler uses this to know how to invoke each agent type. See [Agent Registry API Documentation](./agent-registry-api#agentregistry) for the complete schema definition and [Agent Specification](./agent-specification) for full registration details.

### `AgentVersionDeployment`
Determines which version is active in production for each agent type. **Only one version per agentId can have `environment: 'production'`**.

```typescript
{
  agentId: string; // Agent type (e.g., 'data-collection')
  version: string; // Semantic version (e.g., '1.2.3')
  environment: 'production' | 'staging' | 'development';
  deployedAt: Date;
  deployedBy: string; // Admin user ID
}
```

### `Schedule`
Stores all schedules created by admins. No hardcoded schedules. A schedule can run a single agent or a pipeline of agents, once or repeatedly.

```typescript
{
  id: string;
  name: string;
  description?: string;
  
  // Schedule timing
  repeat: 'once' | 'repeating'; // 'once' for one-time execution, 'repeating' for recurring
  cronExpression?: string; // For repeating schedules (e.g., '0 2 * * 0' for weekly)
  interval?: number; // For repeating schedules (milliseconds, e.g., 3600000 for hourly)
  timezone?: string; // Default: 'America/New_York'
  startAt?: Date; // Optional: when to start the schedule (for 'once' or first run of 'repeating')
  
  // What to execute
  targetType: 'agent' | 'pipeline';
  agentId?: string; // If targetType is 'agent', references AgentRegistry
  pipelineId?: string; // If targetType is 'pipeline', references Pipeline
  
  // Agent parameters (merged with any ID expansions)
  params?: Record<string, any>; // Parameters to pass to agent(s)
  
  // ID expansion configuration (for agents that accept IDs like tickerId, userId, etc.)
  // When an ID parameter is set to 'all', the scheduler will fetch all IDs from the table
  // and create multiple job inputs, running them in batches with stagger delay
  idExpansions?: {
    // Map of parameter name to expansion config
    // Example: { tickerId: { table: 'Ticker', value: 'all' | string } }
    [paramName: string]: {
      table: string; // Database table name (e.g., 'Ticker', 'User')
      value: 'all' | string; // 'all' to expand to all IDs, or specific ID string
      batchSize?: number; // Number of IDs per batch (default: 10)
      staggerDelay?: number; // Delay between batches in milliseconds (default: 1000)
    };
  };
  
  // Retry configuration
  retryConfig?: {
    maxRetries: number;
    backoff: 'exponential' | 'linear' | 'fixed';
    delay: number;
  };
  
  // Timeout
  timeout?: number; // Job timeout in milliseconds
  
  // Priority
  priority?: number; // Job priority (default: 0)
  
  // Status
  enabled: boolean;
  
  // Metadata
  createdAt: Date;
  updatedAt: Date;
  createdBy: string; // Admin user ID
}
```

### `Pipeline`
Defines multi-agent workflows with dependencies. Pipelines can be scheduled just like agents.

```typescript
{
  id: string;
  name: string;
  description?: string;
  steps: Array<{
    stepId: string; // Unique ID within pipeline
    agentId: string; // References AgentRegistry
    dependsOn?: string[]; // Step IDs this step depends on
    parallel: boolean; // Can run in parallel with other steps
    params?: Record<string, any>; // Step-specific parameters
    retryConfig?: {
      maxRetries: number;
      backoff: 'exponential' | 'linear' | 'fixed';
      delay: number;
    };
    timeout?: number;
  }>;
  enabled: boolean;
  createdAt: Date;
  updatedAt: Date;
  createdBy: string; // Admin user ID
}
```

### `ScheduleExecution`
Tracks schedule execution history.

```typescript
{
  id: string;
  scheduleId: string; // References Schedule
  executionTime: Date;
  status: 'success' | 'partial' | 'failed';
  jobsCreated: number;
  jobsEnqueued: number;
  errors?: Array<{
    message: string;
    timestamp: Date;
  }>;
  metadata?: object; // Additional execution metadata
}
```

## Configurations

This is the minimal configuration for the orchestrator. It is stored in the `AgentConfig` table, key: `scheduler`.

```typescript
{
  // Global scheduler settings
  scheduler: {
    enabled: true,
    timezone: 'America/New_York', // Default timezone for schedules
    checkInterval: 60000 // How often to check for due schedules (ms)
  },
  
  // HTTP client configuration for agent invocations
  httpClient: {
    timeout: 300000, // Default timeout (ms) - can be overridden per agent
    maxConcurrentRequests: 50, // Max concurrent agent invocations
    retryConfig: {
      maxRetries: 3,
      backoff: { type: 'exponential', delay: 5000 }
    },
    connectionPool: {
      maxSockets: 100,
      keepAlive: true
    }
  },
  
  // Default ID expansion settings (can be overridden per schedule)
  defaultIdExpansion: {
    batchSize: 10, // Default batch size for ID expansions
    staggerDelay: 1000 // Default delay between batches (ms)
  },
  
  // Monitoring and notifications
  monitoring: {
    enabled: true,
    notifyOnFailure: true,
    notificationChannels: ['email', 'slack'] // Optional
  }
}
```

**Note**: All agent-specific schedules and pipelines are stored in the database tables above, not in the orchestrator configuration. The orchestrator dynamically loads and executes them.

## Execution Results

As a BullMQ worker, the scheduler doesn't return outputs directly. Instead, it writes execution results to the database. The following information is tracked:

**ScheduleExecution Table** - Records each schedule execution:
- `scheduleId`: Reference to the executed schedule
- `executionTime`: When the schedule was executed
- `status`: 'success' | 'partial' | 'failed'
- `jobsCreated`: Number of jobs created from this execution
- `jobsEnqueued`: Number of jobs successfully enqueued
- `errors`: Array of any errors encountered
- `metadata`: Additional execution metadata including:
  - ID expansion details (total IDs, batches processed, batch size)
  - Pipeline execution details (if pipeline was executed)

**AgentJobExecution Table** - Records each individual agent job:
- `jobId`: Unique job identifier
- `agentId`: Agent that will execute the job
- `scheduleId`: Schedule that triggered this job (if applicable)
- `pipelineId`: Pipeline this job is part of (if applicable)
- `pipelineStepId`: Pipeline step this job is part of (if applicable)
- `status`: 'pending' | 'running' | 'completed' | 'failed'
- `priority`: Job priority
- `enqueuedAt`: When the job was enqueued
- `dependencies`: Job IDs this job depends on
- `params`: Agent-specific parameters (merged from schedule + expanded IDs)

**Note**: The scheduler writes execution records to the database immediately after invoking agent HTTP endpoints. Actual job and pipeline status is tracked in the database (`AgentJobExecution` and `ScheduleExecution` tables) and can be queried separately. Agents update their job status in the database as they execute.

## Process

1. **Initialize (BullMQ Worker Startup)**: 
   - Start as a long-running BullMQ worker process
   - Load orchestrator config from database (`AgentConfig` table, key: `scheduler`)
   - Load all enabled schedules from `Schedule` table
   - Load all enabled pipelines from `Pipeline` table
   - Load agent registry from `AgentRegistry` table (discover available agents)
   - Validate agent endpoints are accessible (health checks)
   - Initialize BullMQ queues for schedule execution
   - Register BullMQ workers for processing schedules
   - Initialize job dependency tracking (for pipelines)
   - Initialize ID cache (optional, for performance when processing many IDs)
   - Initialize HTTP client pool for agent invocations
   - Start polling loop to check for schedules that need execution

2. **Agent Discovery**:

   - Query `AgentRegistry` table for all enabled agents (agent type metadata)
   - Query `AgentVersionDeployment` table to determine active production version for each agent
   - Validate that agents referenced in schedules and pipelines exist in registry
   - Load agent HTTP endpoint URLs and configuration from `AgentRegistry`
   - Load agent input schemas to validate job parameters
   - Cache agent metadata (endpoints, authentication, timeouts) for performance

3. **Schedule Polling & Execution**:

   - Worker picks up schedule from queue
   - Load schedule configuration from database
   - Execute schedule (see section 4)
   - For one-time schedules: After execution, mark schedule as disabled or delete it (configurable)
   - For repeating schedules: Schedule next execution based on cron/interval

4. **ID Expansion** (for agents that accept ID parameters):

   The orchestrator expands ID parameters based on `idExpansions` in schedules:

   **4a. ID Expansion Process**:
   - For each parameter in `idExpansions`:
     - If `value = 'all'`:
       - Query the specified table from database (e.g., `Ticker`, `User`)
       - Filter by enabled/active status if applicable
       - Get all IDs from the table
     - If `value` is a specific ID string:
       - Use that single ID
   - If multiple IDs are found (from 'all' expansion):
     - Group IDs into batches based on `batchSize` (default: 10)
     - Create multiple job inputs, one per ID
     - Apply stagger delays between batches based on `staggerDelay` (default: 1000ms) to avoid overloading agents
   - If single ID or no expansion:
     - Create single job input

   **4b. Example: Ticker Expansion**:
   - Schedule has `idExpansions: { tickerId: { table: 'Ticker', value: 'all', batchSize: 10, staggerDelay: 1000 } }`
   - Scheduler queries `Ticker` table and finds 100 enabled tickers
   - Creates 100 job inputs (one per ticker)
   - Processes in batches of 10 with 1 second delay between batches
   - Each job gets `params: { tickerId: '<specific-ticker-id>', ...otherParams }`

   **4c. Example: Specific ID**:
   - Schedule has `idExpansions: { tickerId: { table: 'Ticker', value: 'AAPL' } }`
   - Creates single job input with `params: { tickerId: 'AAPL', ...otherParams }`

5. **Job Creation**:

   For each schedule execution:

   **5a. Load Schedule Configuration**:
   - Load schedule from `Schedule` table
   - Determine target: `agentId` (single agent) or `pipelineId` (pipeline of agents)
   - Validate that target exists in `AgentRegistry` or `Pipeline` table

   **5b. ID Expansion**:
   - Check if `idExpansions` is configured
   - For each parameter in `idExpansions`, expand IDs (see section 4)
   - If multiple IDs found, create multiple job inputs (one per ID)
   - Merge expanded IDs with base `params` from schedule

   **5c. Batch Processing**:
   - If multiple job inputs created (from ID expansion):
     - Group job inputs into batches based on `batchSize` from expansion config
     - Process batches sequentially with `staggerDelay` between batches
     - Within each batch, process jobs in parallel (up to batch size)
   - If single job input:
     - Process immediately
   
   **5d. Job Distribution**:
   - For each job input:
     - Generate unique `jobId` and `executionId`
     - Create execution record in `AgentJobExecution` table with `status: 'pending'`
     - Build execution request with merged parameters (schedule params + expanded IDs)
     - Validate parameters against agent's `inputSchema`
     - Get agent HTTP endpoint URL from `AgentRegistry` table
     - Invoke agent HTTP endpoint (POST to agent endpoint URL)
       - Include authentication headers if configured
       - Set timeout from schedule config or agent default
       - Include `X-Job-Id` and `X-Execution-Id` headers
     - Handle agent response:
       - Agent accepts the job and starts execution
       - Agent updates `AgentJobExecution` table as it runs
       - If agent fails to start: Mark execution as failed, log error
     - Apply stagger delays between batches (if configured for ID expansion)
   - Track job creation in `ScheduleExecution` table

6. **Pipeline Orchestration**:

   For pipeline execution (from `Pipeline` table or schedule with `targetType: 'pipeline'`):

   **6a. Load Pipeline**:
   - Load pipeline definition from `Pipeline` table
   - Validate all referenced `agentId` values exist in `AgentRegistry`

   **6b. ID Expansion** (if configured in schedule):
   - Apply `idExpansions` from schedule (same as single agent expansion)
   - Expand IDs for each parameter that needs expansion
   - If multiple IDs found, create multiple pipeline execution contexts (one per ID)

   **6c. Build Dependency Graph**:
   - Parse pipeline `steps` to build dependency graph
   - Identify steps that can run in parallel (`parallel: true`)
   - Identify steps that must run sequentially (via `dependsOn`)

   **6d. Execute Pipeline Steps**:
   - For each expanded parameter set (if any):
     - Create execution records for all pipeline steps in `AgentJobExecution` table
     - Build dependency graph based on `dependsOn` relationships
     - For steps without dependencies: Invoke agent endpoints immediately
     - For steps with dependencies: Wait for dependency jobs to complete (check `AgentJobExecution.status`)
     - Merge step-specific `params` with expanded IDs and schedule params
     - Invoke agent endpoints with proper sequencing
   - Track pipeline execution in database

7. **Agent Execution**:

   - Orchestrator invokes agent HTTP endpoints asynchronously
   - Agent accepts the job and starts execution
   - Agent executes work and updates `AgentJobExecution` table with status updates
   - Agent reads from and writes to database independently
   - No direct agent-to-agent communication
   - All coordination through database state
   - When agent completes, it updates `AgentJobExecution.status` to 'completed' or 'failed'
   - Agent shuts down after completing its job
   - Orchestrator monitors agent execution by querying `AgentJobExecution` table

8. **Job Dependencies & Status Tracking**:

   - Track job status in `AgentJobExecution` table (pending, running, completed, failed)
   - For pipeline dependencies: Poll `AgentJobExecution.status` to wait for upstream jobs
   - Monitor job progress by querying `AgentJobExecution` table periodically
   - Handle failed jobs with retry logic:
     - Check `AgentJobExecution.error.retryable` flag
     - If retryable and retry count < max: 
       - Re-invoke agent HTTP endpoint after backoff delay (from schedule `retryConfig`)
     - If not retryable: Mark as permanently failed, notify admins
   - Use exponential backoff from schedule config for retries

9. **Batch Processing & Parallelization**:

   - **ID Expansion with Batching**:
     - When `idExpansions` creates multiple job inputs (e.g., 100 tickers):
       - Jobs are grouped into batches based on `batchSize` (default: 10)
       - Within each batch, jobs are processed in parallel (up to batch size)
       - Between batches, `staggerDelay` is applied (default: 1000ms) to avoid overloading agents
       - Example: 100 tickers with `batchSize: 10` = 10 batches, each batch processes 10 jobs in parallel with 1 second delay between batches
     - Agents execute work asynchronously after accepting jobs
   
   - **Single ID Jobs** (no expansion or specific ID):
     - Single job processes with one ID parameter
     - Can run concurrently with other agent jobs
     - Invoked via HTTP endpoint when needed
   
   - **Pipeline Steps**:
     - Steps with `parallel: true` can run concurrently
     - Steps with `dependsOn` run sequentially after dependencies complete
     - If ID expansion creates multiple contexts (e.g., 100 tickers), each context runs the pipeline independently
     - Example: Pipeline with 100 ticker expansions = 100 parallel pipeline executions
     - Each execution invokes agent HTTP endpoints as needed

10. **Scalability Considerations**:

   - **Large ID Sets**: When processing hundreds of IDs (e.g., all tickers):
     - Batch processing prevents overwhelming agent endpoints
     - Stagger delays prevent API rate limits and agent overload
     - Multiple agent invocations happen concurrently (up to `batchSize`)
     - Failed jobs for one ID don't block others
     - Partial failures are handled gracefully (continue with remaining items)
     - Agents can scale independently to handle their own load
   
   - **Dynamic Management**:
     - New IDs are automatically included in next scheduled run when `value: 'all'` is used
     - Disabled/removed IDs are excluded from processing
     - Priority can be set per schedule to influence job priority
   
   - **Resource Management**:
     - `batchSize` in `idExpansions` controls concurrent job execution per batch
     - `staggerDelay` controls rate of batch processing
     - Queue concurrency settings limit total parallel workers
     - Memory and CPU usage scales with batch size and concurrency

11. **Error Handling**:

   - **Agent Invocation Errors** (network, timeout, agent unavailable):
     - Retry with exponential backoff (configured in schedule `retryConfig`)
     - Log errors to database for monitoring (`ScheduleExecution` table)
     - If agent endpoint is unreachable: Mark execution as failed, log error
   
   - **Agent Execution Errors** (agent fails during execution):
     - Agent updates `AgentJobExecution.status: 'failed'` with error details
     - Orchestrator checks `error.retryable` flag
     - If retryable: Re-invoke agent HTTP endpoint after backoff delay (from schedule `retryConfig`)
     - If not retryable: Mark as permanently failed, notify admins
   
   - **Pipeline Dependencies**:
     - Job dependencies can timeout if upstream jobs fail repeatedly
     - Pipeline continues with partial results if some jobs fail (non-blocking)
     - Each pipeline step can have its own retry configuration
   
   - **General**:
     - Notify on critical failures (via configured notification channels)
     - Failed jobs for one schedule don't block others
     - Agents can implement their own retry logic internally
     - Retry configuration from schedule is applied to all job attempts

12. **Metrics Collection**:

   - Agents write metrics to database upon completion
   - Orchestrator queries database for job and pipeline status
   - Track schedule execution history in `ScheduleExecution` table
   - Learning Agent reads metrics from database independently (runs on its own schedule)

## Admin Interface Usage

Admins can create and manage schedules and pipelines through the admin interface. The orchestrator dynamically loads and executes these configurations without any code changes.

### Creating a Schedule

1. **Navigate to Schedules**:
   - Go to `/admin/scheduler/schedules`
   - Click "Create Schedule"

2. **Configure Schedule**:
   - **Basic Info**: Name, description
   - **Target**: Choose `targetType`:
     - **Agent: Select `agentId` from available agents
     - **Pipeline**: Select `pipelineId` from available pipelines
   - **Timing**:
     - **Repeat**: Choose `'once'` for one-time execution or `'repeating'` for recurring
     - **For Repeating**:
       - **Cron**: Provide cron expression (e.g., `"0 2 * * 0"` for weekly Sunday 2 AM)
       - **Interval**: Provide interval in milliseconds (e.g., `3600000` for hourly)
     - **Timezone**: Default is `'America/New_York'`
     - **Start At**: Optional start time (for one-time or first run of repeating)
   - **Parameters**: Set agent parameters (JSON object)
   - **ID Expansions** (optional): For agents that accept ID parameters:
     - Add expansion for each ID parameter (e.g., `tickerId`, `userId`)
     - **Table**: Database table name (e.g., `'Ticker'`, `'User'`)
     - **Value**: 
       - `'all'` to expand to all IDs in the table
       - Specific ID string (e.g., `'AAPL'`) for single ID
     - **Batch Size**: Number of IDs per batch (default: 10)
     - **Stagger Delay**: Delay between batches in milliseconds (default: 1000)
   - **Retry Config**: Configure retry behavior (max retries, backoff, delay)
   - **Timeout**: Job timeout in milliseconds
   - **Priority**: Job priority (default: 0)
   - **Enabled**: Toggle to enable/disable schedule

3. **Save the Schedule**

### Creating a Pipeline

1. **Navigate to Pipelines**:
   - Go to `/admin/scheduler/pipelines`
   - Click "Create Pipeline"

2. **Configure Pipeline**:
   - **Basic Info**: Name, description
   - **Steps**: Add pipeline steps:
     - **Agent**: Select `agentId` for each step
     - **Parameters**: Step-specific parameters (JSON object)
     - **Dependencies**: Define `dependsOn` (step IDs this step depends on)
     - **Parallel**: Toggle if step can run in parallel with others
     - **Retry Config**: Step-specific retry configuration
     - **Timeout**: Step-specific timeout
   - **Enabled**: Toggle to enable/disable pipeline

3. **Save the Pipeline**

4. **Create a Schedule for the Pipeline**:
   - Create a schedule with `targetType: 'pipeline'` and select the pipeline
   - Configure ID expansions if needed (applies to all pipeline steps)

### Example: Query Strategy Agent Schedule

**Schedule**:
- `name`: "Weekly Entity Graph Refresh"
- `repeat`: `'repeating'`
- `cronExpression`: `"0 2 * * 0"` (Sunday 2 AM)
- `targetType`: `'agent'`
- `agentId`: `"query-strategy"`
- `params`: `{ "refreshEntityGraph": true }`
- `idExpansions`: `{ tickerId: { table: "Ticker", value: "all", batchSize: 10, staggerDelay: 1000 } }`

**Result**: Every Sunday at 2 AM, the scheduler:
1. Queries `Ticker` table and finds 100 enabled tickers
2. Creates 100 job inputs (one per ticker)
3. Processes in batches of 10 with 1 second delay between batches
4. Each job gets `params: { tickerId: '<specific-ticker-id>', refreshEntityGraph: true }`

### Example: One-time Agent Execution

**Schedule**:
- `name`: "One-time Data Collection for AAPL"
- `repeat`: `'once'`
- `startAt`: `"2024-01-15T10:00:00Z"`
- `targetType`: `'agent'`
- `agentId`: `"data-collection"`
- `params`: `{ "source": "news" }`
- `idExpansions`: `{ tickerId: { table: "Ticker", value: "AAPL" } }`

**Result**: On January 15, 2024 at 10:00 AM, the scheduler creates a single job with `params: { tickerId: "AAPL", source: "news" }`.

### Example: Pipeline Schedule with ID Expansion

**Pipeline**:
- `name`: "Newsletter Generation Pipeline"
- `steps`: Array of step objects:
  - `{ stepId: "collect", agentId: "data-collection", parallel: false }`
  - `{ stepId: "analyze", agentId: "analysis", dependsOn: ["collect"], parallel: false }`
  - `{ stepId: "generate", agentId: "content-generation", dependsOn: ["analyze"], parallel: false }`

**Schedule**:
- `name`: "Daily Newsletter for All Tickers"
- `repeat`: `'repeating'`
- `cronExpression`: `"0 8 * * *"` (Daily at 8 AM)
- `targetType`: `'pipeline'`
- `pipelineId`: `"newsletter-generation-pipeline"`
- `idExpansions`: `{ tickerId: { table: "Ticker", value: "all", batchSize: 5, staggerDelay: 2000 } }`

**Result**: Every day at 8 AM, the scheduler:
1. Queries `Ticker` table and finds 50 enabled tickers
2. Creates 50 pipeline execution contexts (one per ticker)
3. Processes in batches of 5 with 2 second delay between batches
4. Each context runs the pipeline: collect → analyze → generate (sequential)

## Sequence Diagram

<Mermaid
  chart="
flowchart TD
    subgraph Admin [Admin Interface]
        A1[Admin Creates<br/>Schedule]
        A2[Admin Creates<br/>Pipeline]
    end
    
    A1 --> DB1[(Database<br/>Schedule Table)]
    A2 --> DB2[(Database<br/>Pipeline Table)]
    
    subgraph Worker [BullMQ Worker - Long Running Process]
        S[Scheduler/Orchestrator<br/>BullMQ Worker]
        S --> S0[Poll Database<br/>for Schedules]
        S0 --> S0
    end
    
    DB1 --> S0
    DB2 --> S0
    DB3[(AgentRegistry<br/>Table)] --> S
    
    S0 -->|Schedule Time Arrived| S1[Enqueue to BullMQ<br/>Queue]
    S1 --> S2[BullMQ Worker<br/>Picks Up Job]
    S2 --> S3[Load Schedule<br/>from Database]
    
    S3 --> S4{Target Type?}
    
    S4 -->|Agent| S5[Load Agent Metadata<br/>from AgentRegistry]
    S4 -->|Pipeline| S6[Load Pipeline Steps<br/>from Database]
    
    S5 --> S7{Has ID<br/>Expansion?}
    S6 --> S7
    
    S7 -->|Yes - value: 'all'| S8[Query Table for All IDs<br/>e.g., Ticker table<br/>→ 100 tickers]
    S7 -->|Yes - specific ID| S9[Use Single ID<br/>e.g., tickerId: 'AAPL']
    S7 -->|No| S10[Create Single Job Input]
    
    S8 --> S11[Group IDs into Batches<br/>batchSize: 10<br/>100 IDs → 10 batches]
    S11 --> S12[Create Job Inputs<br/>One per ID<br/>100 IDs = 100 inputs]
    
    S9 --> S13[Create Single Job Input<br/>with specific ID]
    
    S12 --> S14[Process Batches Sequentially<br/>with staggerDelay between batches]
    S13 --> S14
    S10 --> S14
    
    S14 --> S15[Within Batch: Process Jobs<br/>in Parallel up to batchSize]
    
    S15 --> S16{Is Pipeline?}
    S16 -->|Yes| S17[Build Dependency Graph<br/>from Pipeline Steps]
    S17 --> S18[Execute Steps with Dependencies<br/>Sequential or Parallel]
    S18 --> S19[Invoke Agent HTTP Endpoints<br/>for Each Step]
    S16 -->|No| S19[Invoke Agent HTTP Endpoints<br/>for Single Agent]
    
    S19 --> AG1[Agent HTTP Endpoint<br/>POST /execute]
    
    subgraph Agents [Agent Executes - One-off Execution]
        direction TB
        AG2[Agent Accepts Job<br/>Starts Execution]
        AG3[Agent Executes Work<br/>Reads/Writes to Database]
        AG4[Agent Updates DB<br/>AgentJobExecution table]
        AG5[Agent Writes Results<br/>to Database]
        AG6[Agent Shuts Down<br/>After Completion]
    end
    
    AG1 --> AG2
    AG2 --> AG3
    AG3 --> AG4
    AG4 --> AG5
    AG5 --> AG6
    
    AG6 --> DB4[(Database<br/>All agents read/write<br/>independently)]
    
    DB4 --> S21[Orchestrator queries DB<br/>AgentJobExecution table<br/>for job status]
    S21 --> S22[Write to ScheduleExecution<br/>Table]
    S22 --> S0
"
/>
